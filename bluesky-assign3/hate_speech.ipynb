{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6efa6f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from transformers import get_scheduler\n",
    "from torch.optim import AdamW\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "102cba1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>count</th>\n",
       "      <th>hate_speech</th>\n",
       "      <th>offensive_language</th>\n",
       "      <th>neither</th>\n",
       "      <th>class</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>!!! RT @mayasolovely: As a woman you shouldn't...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>!!!!! RT @mleew17: boy dats cold...tyga dwn ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>!!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>!!!!!!!!! RT @C_G_Anderson: @viva_based she lo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>!!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  count  hate_speech  offensive_language  neither  class  \\\n",
       "0           0      3            0                   0        3      2   \n",
       "1           1      3            0                   3        0      1   \n",
       "2           2      3            0                   3        0      1   \n",
       "3           3      3            0                   2        1      1   \n",
       "4           4      6            0                   6        0      1   \n",
       "\n",
       "                                               tweet  \n",
       "0  !!! RT @mayasolovely: As a woman you shouldn't...  \n",
       "1  !!!!! RT @mleew17: boy dats cold...tyga dwn ba...  \n",
       "2  !!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...  \n",
       "3  !!!!!!!!! RT @C_G_Anderson: @viva_based she lo...  \n",
       "4  !!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"labeled_data.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9436fe78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 1, 0])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = df[['tweet', 'class']]\n",
    "#verify unique target values\n",
    "data['class'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "deefb7b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\17987\\AppData\\Local\\Temp\\ipykernel_33208\\1316877197.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['clean_text'] = data['tweet'].apply(preprocess)\n"
     ]
    }
   ],
   "source": [
    "def preprocess(text):\n",
    "    text = re.sub(r\"http\\S+\", \"\", text)  #remove URLs\n",
    "    text = re.sub(r\"[^a-zA-Z]\", \" \", text)  #remove special characters and numbers\n",
    "    text = text.lower()  #convert to lowercase\n",
    "    words = text.split()\n",
    "    return \" \".join(words)\n",
    "\n",
    "data['clean_text'] = data['tweet'].apply(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e6676117",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 17843, Validation: 1983, Test: 4957\n",
      "Using device: cuda\n",
      "Starting training for 3 epochs...\n",
      "\n",
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1116/1116 [03:49<00:00,  4.87it/s, loss=1.06]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.2933\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 124/124 [00:09<00:00, 12.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation F1-Score (weighted): 0.8795\n",
      "\n",
      "Epoch 2/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1116/1116 [04:17<00:00,  4.33it/s, loss=0.029] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.2068\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 124/124 [00:09<00:00, 12.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation F1-Score (weighted): 0.9128\n",
      "\n",
      "Epoch 3/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1116/1116 [04:54<00:00,  3.79it/s, loss=0.405]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.1424\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 124/124 [00:03<00:00, 37.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation F1-Score (weighted): 0.9100\n",
      "\n",
      "Final evaluation on test set:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 310/310 [00:08<00:00, 38.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score     support\n",
      "Hate Speech    0.545872  0.416084  0.472222   286.00000\n",
      "Offensive      0.942784  0.961699  0.952148  3838.00000\n",
      "Neither        0.908981  0.899160  0.904043   833.00000\n",
      "accuracy       0.919710  0.919710  0.919710     0.91971\n",
      "macro avg      0.799212  0.758981  0.776138  4957.00000\n",
      "weighted avg   0.914203  0.919710  0.916374  4957.00000\n",
      "Model saved to 'hate_speech_classifier' directory\n",
      "\n",
      "Example predictions:\n",
      "Text: 'I love everyone regardless of their background'\n",
      "Prediction: Neither\n",
      "\n",
      "Text: 'You're an idiot and nobody likes you'\n",
      "Prediction: Neither\n",
      "\n",
      "Text: 'I hate people from that country, they should all die'\n",
      "Prediction: Hate Speech\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class HateSpeechDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_length=128):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        text = str(self.texts[idx])\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        # Tokenize the text\n",
    "        encoding = self.tokenizer(\n",
    "            text,\n",
    "            truncation=True,\n",
    "            padding='max_length',\n",
    "            max_length=self.max_length,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        \n",
    "        # Return as dictionary\n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'label': torch.tensor(label, dtype=torch.long)\n",
    "        }\n",
    "\n",
    "def train_epoch(model, dataloader, optimizer, scheduler, device):\n",
    "    \"\"\"Train the model for one epoch\"\"\"\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    \n",
    "    progress_bar = tqdm(dataloader, desc=\"Training\")\n",
    "    for batch in progress_bar:\n",
    "        # Move batch to device\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['label'].to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            labels=labels\n",
    "        )\n",
    "        \n",
    "        loss = outputs.loss\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Update progress bar\n",
    "        progress_bar.set_postfix({'loss': loss.item()})\n",
    "    \n",
    "    return total_loss / len(dataloader)\n",
    "\n",
    "def evaluate(model, dataloader, device):\n",
    "    \"\"\"Evaluate the model on validation data\"\"\"\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    true_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(dataloader, desc=\"Evaluating\"):\n",
    "            # Move batch to device\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['label'].to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(\n",
    "                input_ids=input_ids,\n",
    "                attention_mask=attention_mask\n",
    "            )\n",
    "            \n",
    "            # Get predictions\n",
    "            preds = torch.argmax(outputs.logits, dim=1).cpu().numpy()\n",
    "            predictions.extend(preds)\n",
    "            true_labels.extend(labels.cpu().numpy())\n",
    "    \n",
    "    # Calculate metrics\n",
    "    report = classification_report(true_labels, predictions, target_names=['Hate Speech', 'Offensive', 'Neither'], output_dict=True)\n",
    "    conf_matrix = confusion_matrix(true_labels, predictions)\n",
    "    \n",
    "    return report, conf_matrix, predictions, true_labels\n",
    "\n",
    "# def plot_confusion_matrix(conf_matrix, class_names):\n",
    "#     \"\"\"Plot confusion matrix as heatmap\"\"\"\n",
    "#     plt.figure(figsize=(10, 8))\n",
    "#     sns.heatmap(\n",
    "#         conf_matrix, \n",
    "#         annot=True, \n",
    "#         fmt='d', \n",
    "#         cmap='Blues', \n",
    "#         xticklabels=class_names,\n",
    "#         yticklabels=class_names\n",
    "#     )\n",
    "#     plt.xlabel('Predicted')\n",
    "#     plt.ylabel('True')\n",
    "#     plt.title('Confusion Matrix')\n",
    "#     plt.tight_layout()\n",
    "#     plt.savefig('confusion_matrix.png')\n",
    "#     plt.close()\n",
    "\n",
    "def train_and_evaluate(df, model_name=\"distilbert-base-uncased\", epochs=3, batch_size=16, learning_rate=5e-5):\n",
    "    \"\"\"Train and evaluate the model\"\"\"\n",
    "    # Split data into train, validation, and test sets\n",
    "    train_df, test_df = train_test_split(df, test_size=0.2, random_state=42, stratify=df['class'])\n",
    "    train_df, val_df = train_test_split(train_df, test_size=0.1, random_state=42, stratify=train_df['class'])\n",
    "    \n",
    "    print(f\"Train: {len(train_df)}, Validation: {len(val_df)}, Test: {len(test_df)}\")\n",
    "    \n",
    "    # Load pre-trained tokenizer and model\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(\n",
    "        model_name, \n",
    "        num_labels=3,\n",
    "        id2label={0: \"Hate Speech\", 1: \"Offensive\", 2: \"Neither\"},\n",
    "        label2id={\"Hate Speech\": 0, \"Offensive\": 1, \"Neither\": 2}\n",
    "    )\n",
    "    \n",
    "    # Create datasets\n",
    "    train_dataset = HateSpeechDataset(train_df['clean_text'].values, train_df['class'].values, tokenizer)\n",
    "    val_dataset = HateSpeechDataset(val_df['clean_text'].values, val_df['class'].values, tokenizer)\n",
    "    test_dataset = HateSpeechDataset(test_df['clean_text'].values, test_df['class'].values, tokenizer)\n",
    "    \n",
    "    # Create dataloaders\n",
    "    train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_dataloader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "    test_dataloader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "    \n",
    "    # Check if GPU is available\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"Using device: {device}\")\n",
    "    model.to(device)\n",
    "    \n",
    "    # Set up optimizer and scheduler\n",
    "    optimizer = AdamW(model.parameters(), lr=learning_rate)\n",
    "    num_training_steps = epochs * len(train_dataloader)\n",
    "    scheduler = get_scheduler(\n",
    "        \"linear\",\n",
    "        optimizer=optimizer,\n",
    "        num_warmup_steps=0,\n",
    "        num_training_steps=num_training_steps\n",
    "    )\n",
    "    \n",
    "    # Train the model\n",
    "    print(f\"Starting training for {epochs} epochs...\")\n",
    "    for epoch in range(epochs):\n",
    "        print(f\"\\nEpoch {epoch+1}/{epochs}\")\n",
    "        train_loss = train_epoch(model, train_dataloader, optimizer, scheduler, device)\n",
    "        print(f\"Training loss: {train_loss:.4f}\")\n",
    "        \n",
    "        # Evaluate on validation set\n",
    "        val_report, val_matrix, _, _ = evaluate(model, val_dataloader, device)\n",
    "        print(f\"Validation F1-Score (weighted): {val_report['weighted avg']['f1-score']:.4f}\")\n",
    "    \n",
    "    # Final evaluation on test set\n",
    "    print(\"\\nFinal evaluation on test set:\")\n",
    "    test_report, test_matrix, test_preds, test_labels = evaluate(model, test_dataloader, device)\n",
    "    \n",
    "    # Print results\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(pd.DataFrame(test_report).T)\n",
    "    \n",
    "    # Plot confusion matrix\n",
    "    #plot_confusion_matrix(test_matrix, ['Hate Speech', 'Offensive', 'Neither'])\n",
    "    \n",
    "    # Save the model\n",
    "    model.save_pretrained(\"hate_speech_classifier\")\n",
    "    tokenizer.save_pretrained(\"hate_speech_classifier\")\n",
    "    print(\"Model saved to 'hate_speech_classifier' directory\")\n",
    "    \n",
    "    return model, tokenizer, test_report\n",
    "\n",
    "def predict_text(text, model, tokenizer, device):\n",
    "    \"\"\"Make prediction for a single text\"\"\"\n",
    "    model.eval()\n",
    "    encoding = tokenizer(\n",
    "        text,\n",
    "        truncation=True,\n",
    "        padding='max_length',\n",
    "        max_length=128,\n",
    "        return_tensors='pt'\n",
    "    )\n",
    "    \n",
    "    # Move to device\n",
    "    input_ids = encoding['input_ids'].to(device)\n",
    "    attention_mask = encoding['attention_mask'].to(device)\n",
    "    \n",
    "    # Make prediction\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        pred = torch.argmax(outputs.logits, dim=1).item()\n",
    "    \n",
    "    labels = {0: \"Hate Speech\", 1: \"Offensive Language\", 2: \"Neither\"}\n",
    "    return labels[pred]\n",
    "\n",
    "\n",
    "# Train and evaluate model\n",
    "model, tokenizer, test_report = train_and_evaluate(\n",
    "    data, \n",
    "    model_name=\"distilbert-base-uncased\",  # You can change to other models\n",
    "    epochs=3,\n",
    "    batch_size=16,\n",
    "    learning_rate=5e-5\n",
    ")\n",
    "\n",
    "# Example predictions\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "examples = [\n",
    "    \"I love everyone regardless of their background\",\n",
    "    \"You're an idiot and nobody likes you\",\n",
    "    \"I hate people from that country, they should all die\"\n",
    "]\n",
    "\n",
    "print(\"\\nExample predictions:\")\n",
    "for example in examples:\n",
    "    prediction = predict_text(example, model, tokenizer, device)\n",
    "    print(f\"Text: '{example}'\")\n",
    "    print(f\"Prediction: {prediction}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1973ff3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Offensive Language'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"example\"\n",
    "predict_text(text, model, tokenizer, device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fashionmnist",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
